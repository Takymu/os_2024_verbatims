Лекция 05.02.2024. 

Воспитательная беседа

Познакомились вы например с девушкой, даже не просто познакомились, а пошли знакомиться с её родителями. И вот ваш будущий тесть спрашивает "где вы работаете". И вы отвечаете - в сбертехе. А он спрашивает "а, случайно, не сбертройка?" И вот в руках тестя уже появляется табуретка. Стоит ли оно тех денег, которые вам там платили?

Вы в общем-то все понимаете, что косорукие программисты, особенно команды косоруких программистов, они способны поставить на уши милионный город, разорить компанию, уронить самолет. Что-нибудь поджечь, взорвать, утопить, заморозить, что еще можно сделать, используя IoT.

Собственно, лекция.

Сначала мы изучим те преимущества, которые дают треды, не пользуясь самими тредами. Теоретическую базу мы прошли в предыдущем семестре - семафоры, мутексы, гармоническое взаимодействие.

Сейчас по сути вы уже сочтены достаточно взросленькими. Вы будете проходить параллелизм в моем курсе, в джаве, теории параллелизма и сетях. Еще у вас будут прерывания в микроконтроллерах. То есть все профильные курсы семестра у вас содержат параллелизм. Очень долго индустрия избегала этого в таких масштабах. Но теперь у производителей железа сложилось впечатление, что человечество этому научилось. Поэтому если вы не научитесь параллелизму, вы будете неконкуретноспособны.

Когда у нас разделяемая память, у нас возникает куча проблем с критическими данными. Но у нас возникают решения в виде мутексов, семафоров и прочего. На самом деле есть гораздо более страшная проблема, с которой вы столкнетесь в следующем семестре - распределенные данные. В сетях вы даже не можете узнать, потерялся ли у вас пакет, вы можете только делать вывод, что он не пришел за заданное время. Вы можете сделать вывод о том, что ваш партнер куда-то делся. Потом он через два дня приходит и спрашивает "а где моя транзакция?". Если у вас транзакционные данные, начинается ужас.
В следующем году вы начнете изучать вещи, где решения проблем нет.

Вот мы в прошлом году проходили процессы. Процесс, или задача - это некий образ процесса, виртуальная память, атрибуты процесса в ядре. В не-Unix системах процессы называют задачами. Мы знаем, что в рамках каждого процесса программа исполняется последовательно, как будто она исполняется в однозадачной ОС. Вы можете программировать примерно также, как вас учили на первом курсе. Если задача требует распараллеливания, вам надо запускать несколько процессов, вопрос в том, как.
Трубы, сокеты, разделяемые файлы и блокировка участков файлов, семафоры, очереди сообщений, разделяемая память Xenix. Первые три - гармоническое взаимодействие, которое позволяет получить преимущества многопоточности не нарываясь на проблемы с ней.
Unix не был пионером в многопоточности, появилась она в IBM MVS - OS/390 - z/OS. В 70-е годы устоялся термин тред для вот таких сущностей.

Ну и вот - поток. Определение потока, которое можно выдрать из нескольких фраз, которые говорились раньше, и из определения контекста потока, которое я вас пытался заставить использовать как категориальный вопрос. 
Набор регистров процессора, который нужно сохранить, чтобы при переключении процессов процесс не заметил. - контекст процесса.

Поток - единица программного кода, для которой создается иллюзия последовательного выполнения.
Или системный или пользовательский программный объект, создаваемый для управления потоком в предыдущем смысле. 

Если у вас несколько ядер или гипертрединг, то иллюзия параллелизма может не быть иллюзией. 

Потоком также называют системный или пользовательский объект, который управляет нитями в первом смысле.

В джаве поток - это объект языка джавы. Вы его инстанциируете и говорите ему run. В pthread library объектов нет, есть непрозрачный тип. Непрозрачный тип - объект, у которого все атрибуты данных инкапсулированы.

С семафорами, даже если вы знаете, как они устроены внутри, вам все равно не стоит пользоваться этим знанием. Если вы пользуетесь им правильно, то есть через методы семафора, вам знать это не нужно. Однако если вы делаете это иначе, значит вы это делаете неправильно.

Определение потока не будет вынесено в категориальные вопросы, по крайней мере в этом сезоне. Вы можете найти определение нити "минимальная единица планирования". Однако оно не покрывает такое понятие как hyperthreading. Да и непонятно, что такое планирование. 
У Вахалии есть интересная альтернатива понятия нити "контрольная точка" или "точка управления" - у каждой нити есть место, в которой у неё на данный момент находится исполнение. 

Почти во всех системах, с которыми вам придется иметь дело, потоки подчинены процессам. В рамках процессов создается один или несколько потоков, может быть и 0 потоков - процесс зомби. На самом деле более интересная вещь, что традиционные процессы, которые мы проходили в прошлом сезоне, имеют один поток. На самом деле это все теоретически не обязательно, но мне не хватит душевных сил объяснить другие варианты и почему они не так привлекательны. В системах есть процессы, в процессах есть потоки. А есть ядро, которое не является процессом и внутри ядра есть свои потоки. У линукс, солярис и виндоус есть внутриядерная многопоточность. Системный поток и ядерный поток это немножко разные вещи, хотя логически это может считаться одним и тем же. Ну короче потом по ходу разберемся, пока достаточно это самое.

Что дает многопоточность по сравнению с процессами. У потоков разделяемое адресное пространство. Когда вы переключаете процессы, переключение памяти - это самая дорогая операция. У диспетчера памяти есть TLB, который надо сбрасывать при переключении процессов. И пока он не заполнится, у вас будет просадка производительности, довольно ощутимая, причем она немного по сволочному будет происходить. Первая команда вашего процесса по счетчикам производительности исполнилась вроде быстро, но при этом ваш процесс лагает. Это довольно неприятно, поэтому переключать нити одного процесса дешевле, чем процессы. Переключая потоки вы получаете все преимущества разделяемой памяти. Главные из них - высокая скорость доступа и возможность произвольного доступа, полезно при больших разделяемых данных. 
Многие из вас может быть слышали генерацию картинок рейтресинг. Вы можете генерировать разные блики, зеркала. Phong вам дает это криво. При этом когда вы луч кидаете, вы не знаете, куда он попадет. А если поверхность рассеивающая, луч может попасть сразу во много объектов. Предсавьте, что вы делаете это в реальном времени - у вас есть какие-нибудь кракозябры, которые пытаются вас убить, а вам надо все это просчитывать. Надо делать либо последовательно - изменение сцены - рейтрейсинг, либо костыли городить. 
Мы проходили разделяемую память mmap, и вам не гарантируют, что он в разных процессах упадет на одно и то же место, то есть вы даже указатели сделать не можете. На этой оптимистичной ноте давайте сделаем перерыв.

Вам давался какой-то абстрактный объект, который вы могли замапать и этот сегмент памяти у вас мог разделяться между процессами. Вы получаете все недостатки раделяемой памяти, потокобезопасность.. Ну, щас объясню, а потом объясню.

Вы не можете размещать указатели на разделяемую память, поскольку у вас нет гарантий, что в разных процессах они попадут на одни и те же адреса. Поэтому вместо разделяемой памяти сейчас использоваться потоки.
MPI - библиотека или фреймворк для параллельных вычислений.

Это что хорошего в потоках. Что плохого:
первое плохое, разделяемая память вносит проблемы с критическими секциями. Во-вторых, у вас все потоки в одной памяти. Если вы честно отлаживали программы на ассемблере, вы видели, что ошибки работы с памятью они сволочи каскадные. Программа падает не сразу, а постепенно, сначала портится один индекс в массиве, из-за него портится что-то еще, и так далее, в итоге когда программа упала, вы часто не сможете востановить, что произошло.

Процесс - единица изоляции. Если в процессе что-то идет не так, ОС дает ему бдыщ по башке и больше ничего в процессе не происходит.

В нитях же если одна нить завершается аварийно, то вам придется завершать аварийно все остальные нити. 

Все нити работают с одними правами из-под одной учетной записи.

История POSIX тредов. Пока виндузисты и виэмэсовцы говорили, что у них есть такая замечательная вещь, как поток, пользователи юникс говорили, что у них есть гармоническое взаимодействие. Однако когда получили распространение системы реального времени, стало ясно, что так жить нельзя. 

Есди вы будете искать по манам соляриса треды, вы увидите, что они там есть. Тем не менее в 95 году появились POSIX треды и все, что мы проходим, в стандарте осталось. Одна из особенностей, которые мы не видим в других частях стандарта. 

На момент, когда треды создавались, была куча проприетарных реализаций многопоточности. Поэтому в начале всех типов и функций есть префикс pthread. Однако на posix треды есть жалобы по производительности. 

posix треды есть во всех системах unix. Есть некоторые realtime extensionы, которые мы будем изучать, но не в целях реалтайма. 

Зачем нужна многопоточность?
- улучшение времени реакции интерактивных программ
- повышение производительности серверных приложений
- использование многопроцессорных машин и многоядерных процессоров для вычислений, чтобы загрузить все ядра, которые у вас есть.
- приложение мультимедиа и реального времени
- iobound программы, программы - ориентированные на ввод-вывод. 
- весь интернет вещей, реалтаймовые задачи, бортовые компьютеры самолетов, космических аппаратов.

Есть два класса задач - реалтайм и shared time обработка событий. Если у вас есть космический аппарат, которому надо корректировать орбиту. Если он её скорректирует на 20 секунд позже, то он улетит уже не туда. Вот есть такая игрушка, Kerbal Space Program, кто в неё играл? Там это хорошо видно. (лайк Иртегову за KSP, прим. ред.) Если у вас самолет или автомобиль летит не туда, вам надо подкорректировать. Вот в Америке самолет с вертолетом столкнулись, потому что система противодействиея столкновениям не успела среагировать.

Разделенное время - когда вам надо хорошее среднее время реакции. Среднее время реакции системы разделенного времени гораздо лучше, чем гарантированное время реакции системы реального времени. Человека обычно интересует среднее время реакции, которое, как ни странно, оптимизировать проще, его можно уоптимизировать гораздо дальше. Среднее время реакции - параметр, который нам важен в разработке приложений. Большая часть программистких позиций - shared time, реальное время.

Например, вы хотите показывать кино со звуком. Все, кто смотрит звук и кино, хотят, чтобы они одновременно шли.

Улучшение времени реакции:
- фоновое скачивание страниц в браузере
- фоновый ввод-вывод
- фоновая проверка орфографии
- фоновое переразбиение текста на страницы в WYSUWYG текстовых процессорах.

Серверные приложения. Запросы приходят в сетевой адаптер, затем вы их как-то обрабатываете, происходит обращение в базу данных, она обращается к диску, диск их как-то обрабатывает, и данные идут обратно в сетевой интерфейс. Можно пока одни данные считываются, другие могут обрабатываться, третьи в это время считываются с диска, таким образом по производительности может быть выигрыш в разы. Есть ситуации, когда выигрыша быть не может, их вы будете изучать в следующем году. 
Однако если какой-то из этих запросов захватывает критическую секцию, пока он из неё не вылезет, другие запросы обрабатываться не смогут.

Что мешало в 90-е годы перейти к многопоточности?
1. компиляторы, которые к 90-м годам были достаточно умные и генерировали код, преобразуя его по дороге довольно сильно в плане оптимизации. С другой стороны, когда такой код пытались запустить параллельно, выяснялись всякие удивительные чудеса. 
2. если мы посмотрим в стандартную библиотеку языка Си, мы там увидим много функций, который по смыслу невозможно сделать многопоточными или надо что-то придумать. Хотя насчет невозможно я загнул, я пытался в прошлом семестре вам что-то рассказывать. Например, функция маллок, про которую я вам рассказывал в прошлом сезоне, он не потокобезопасен. Если вы просто вставите в него семафоры на входе и выходе, которые зовут очень много маллоков. 
В Си++ есть STL, который я люблю, но он зовет много маллоков. Выходы есть, но они как бы.. Куча делится на арены, каждому потоку выдается своя арена, и пока они не пересекаются, все хорошо. Еще веселый вариант, когда вы в одном потоке зовете malloc, в другом free - жесткий контрпример на все эти арены. Многопоточный маллок - настолько грустная тема, говорят, что в системном программировании все изобретено, это ложь. Если вы изобретете, то какой-нибудь Маллок Сидорова может войти в историю. Вот вы запускаете многопоточную программу, запускаете в отладчике, а отладчик не понимает, что происходит.
3. Проблема еще была в головах. Программисты не умели писать многопоточные программы, а попыткам научить сопротивлялись. Я и сейчас эти попытки сопротивления вижу. Еще сопротивление было на уровне языков. Был такой язычок Ada. У неё есть близкий родственник - Go, куда более близкий, чем вы можете себе представить. Posix треды рассчитаны на компилятор языка Си.

Смотрите, представим себе, что самое очевидное в плане многопоточности может оптимизировать оптимизирующий компилятор. Убрать многопоточность он не может, потому что компиляторы Си не убирают вызовов функций. Какой основной механизм взаимодействия тредов порождает наибольшую опасность? Разделяемая память. Какая опасность нас поджидает при работе с ней? Компилятор может записать данные в регистры, в них посчитать и записать обратно. 

Есть два типа трагедий. Первый тип - если разделяемое значение лежит в регистре, то остальные нити не увидят его изменения вообще. Во-вторых, мы с вами проходили критические секции и понимаем, что порядок изменения разделяемых данных бывает важен. Вы проходить не будете, но в джаве и в си есть такая длиннющая секция - модель памяти. Основная ручка управления ей - слово volatile. 
Слово volatile в языке Си было с самого начала, потому что иначе нельзя было бы писать на нем ядра операционных систем. Однако слова этого в стандарте не было до 2011 года. И каждое ядро операционной системы было заточено под компиляцию определенным Си компилятором. Линукс сейчас компилируется только gcc. 

А дальше начинает самая веселуха. Потому что чтобы этого избежать..
А, кстати, мне очень понравилось описание модели памяти в GO: для любой последовательности операций которая не содержит вызовов примитивов синхронизаций порядок исполнения не определен. Вот, вся модель памяти. 

Одна из моралей этой истории, что компилятор обязан узнавать в коде примитивы синхронизации, а для этого он должен знать, какую многопоточную библиотеку вы используете. Поэтому у gcc есть опция pthreads, а есть другие опции, для разных сборок они разные. У сановского компилятора немножко хитрее.

Тем не менее вот это вот все было сделано, и мы пожинаем плоды. OpenMP и MPI - диалект языка Си, который там находится на уровне языка. Однако OpenMP и Posix треды лучше совместно не использовать.

Главное препятствие к многопоточному программированию, которое у нас осталось, это то, что находится у людей в головах. Я надеюсь в ходе этого семестра с этим препятствием справиться. Ну и вот, библиотеки. С библиотеками было довольно много сделано, если вы читали философию, знаменитая книжка "дизайн и эволюция языка Си++". Там много интересных соображений высказываются. Там есть такая вещь, философия Unix и Си, "вы не платите за то, чем не пользуетесь". Но с тех пор, как была сделана единая библиотека libc для одно и многопоточных программ, вы платите за многопоточность. Тем не менее да, вот многопточность, при всех её достоинствах, нарушает это правило.

На самом деле мы дальше увидим некоторые примеры того, как обходили эту плату, но тоже не бесплатно.

В солярисе есть два состояния, есть состояние safe, которую вы теоретически можете использовать в многопточной программе, однако она плохо масштабаруема. Есть MT safe, что означает, что функция хорошо оптимизирована под многопоточность. Есть тонкие блокировки и грубые блокировки. Грубые вы ставите на большие участки кода, гарантируете, что все работает правильно, но у вас плохая масштабируемость. Второй вариант - тонкая блокировка, когда вы разбиваете вашу критическую секцию на много мелких секций. Казалось бы, это лучше. На самом деле - нифига. Это во-первых усложняет кодируемость, во-вторых сама по себе блокировка не бесплатная. Они выключают кучу вещей по производительности, очищают кэш, заставляют компилятор отказаться от размещения значений в регистрах.

Просто обеспечение когерентности кэша разделяемой переменной по стоимости как целочисленное деление с плавающей точкой. В задаче вычисления числа пи надо сумму ряда хранить. Если вы будете хранить её в локальных переменных, все будет работать быстро, если вы перенесете её в глобальную область, производительность сядет в два раза.
Ilya_, [26.03.2025 16:01]
ОСи, лекция 26.03.2025

Мы подошли к одному интересному моменту, многие из вас пытаются сдавать задачки про прокси и прочие интересные моменты. И из того, что мы проходили раньше, не очень-то ясно, как их писать.

Я вас хотел просить, вы на джаве уже приложения с GUI писали?
Да.
На чем? 
На JavaFX.

Меня интересуют какие-то загадочные стажировки по джаваскрипту.

Современные программисты чаще всего с этим сталкиваются в графических интерфейсах.

Как вообще программа на javafx отличается от тех программ, которые вы писали во всех остальных случаях?
Они событийно-ориентированные.
Как событийно-ориентированные программы отличаются от того, к чему вы привыкли?
Вы навешиваете обработчики, пишете какие-то функции в случае tkinter или методы в java, регистрируете их в tkinter или в javafx, и вас дергает этот самый javafx. У вас нет мейна как такового, вас зовет фреймворк. Та программа, которую вы пишете, представляет собой не некую простыню которая исполняется от начала и до конца, а набор кусочков кода, функций или методов, которые дергаются в ответ на события.
Этот подход применяется шире, чем вы можете ожидать, он даже не был придуман для целей разработки GUI. В решении задач проде прокси он вам может помочь. Он заслуживает отдельной лекции. 
К сожалению, следующую среду меня не будет. Повод для оптимизма есть, что это мне вреда не принесет. Один глаз они мне починили. Я даже не просил никого открыть презентацию.

То есть событийно-ориентированная архитектура. Большая часть из вас большую часть карьеры будет заниматься приложениями, которые так или иначе находятся в сфере применения этих архитектур.

То, что мы решаем в нашем практикуме, это сетевые приложения. Модное нынче слово микросервисы тоже в этом стиле написано. То, что обычно называют мобильными приложениями, ядра ОС, приложения реального времени, игрушки. В общем, почти все, что не является вычислительными задачами. 

Тех, кто хочет заниматься машинным обучением, я разочарую, потому что это увлечением ненадолго. Также, как было с optical character recognition. Оно затихнет, исчерпав потенциал.

Я воспользовался книжкой Event-Driven programming introduction tutorial history. Книжка мне понравилась, она может излагать материал немножко не так, как вы можете его изучать в других местах.
Вам приходят события, они приходят из внешнего мираа.

events -> dispatcher -> (handler1, handler2, ... handler n) диспетчер, к которому события приходят, распределяет их между хэндлерами. Говоря о событийно-ориентированных архитектурах вообще, вам стоит привыкнуть к мысли, что одни и те же вещи в разных книжках могут рисоваться иначе.
Что отделят эти архитектуры от других событий? Голливудский принцип - не звоните нам, мы позвоним вам. 

До этого момента все, что вы делали, вы привыкли пользоваться библиотеками. Вы зовете main и в нем вы зовете какие-то вещи.

В данном контексте появляется понятие фреймворка.
Что такое фреймворк? Несколько библиотек? Нет. То, что описывает приложение? Тоже мимо. Среда? Опять же, среда слишком широкая.
Библиотека - набор функций, которые зовете вы.
Фреймворк - некая хрень, которая зовет вас. Вы делаете обработчики, регистрируете их в фреймворке и он зовет их в какие-то известные ему моменты.
Библиотека и фреймворк - это два разных и логически несовместимых подхода к реализации API. Главное отличие - библиотеку зовете вы, фреймворк зовет вас.
В javafx вы пишете методы объектов, и они зовутся сами по неизвестным вам причинам. Точнее известным, но в неожиданном для вас порядке. 
Когда вас позвали, вы должны узнать, что это за событие, может сказать что-то другое фреймворку про это событие. Во фреймворках есть функции библиотек.
На самом деле фреймворки для GUI могут иметь какие-то другие примочки. Когда вы описываете GUI, вы можете просто создавать объекты, как в tkinter, сами создаете, сами расставляете по окошку. В мобильных фреймворках вы в каком-нибудь xml пишете формат и ссылки на код, который будет исполняться.

Ilya_, [26.03.2025 16:01]
А как в таком виде концепция видимости переменной работает?
Во-первых область видимости зависит от языка. Вы, конечно, можете вешать в обработчики глобальные переменные. Но событийно ориентированные архитектуры дают примерно два десятка известных мне причин, по которым это зло.
Обработчик, хотя и выглядит как функция, это не функция, это объект. С обработчиком связан какой-то блок переменных состояния.
Методы обработчика меняют это состояние и переводят его в какие-то другие состояния.

В джаве вы не можете написать просто функцию, вы всегда пишете объект. Методы этого объекта и дергаются. Вы можете создать в этом объекте data memberы, которые будут полями этого обработчика. Таким образом вы храните состояние.
Анекдот в том, что обработчик зовется из контекста менеджера событий и его локальные переменные не переживают эти вызовы. Менеджер его позвал, он вернулся - все, локальные переменные исчезли. Многие приемы программирования, в том числе локальные динамические массивы С99 здесь плохо работают.
Если вам надо открыть несколько одинаковых окон, вы инстанциируете несколько объектов и в каждом свое состояние.
Мы увидим как это мапируется на сетевой сервер.

Фреймворки, написанные на не ООП языках, как Си или сырой Win32 API работают похоже, первым параметром обработчика идет указатель на некоторую структуру, которая называется блоком переменных состояния. Для драйвера к примеру это может быть блок состояния устройства, чтоб он понял, что это за устройство.

Именно поэтому у всех функций драйвера идет Device Control Block первым параметром.

На самом деле во фреймворках далеко не все события внешние. Графический интерфейс выглядит так, пользователь нажимает меню, у него открывается диалог. Меню рисует сам фреймвор, сам обрабатывает события от мыши, меню генерирует командные события. Эти события передаются файловому диалогу.

В javafx это может быть немного не так, но в реальных фреймворках довольно большая доля событий приходит снаружи. Здесь можно продемонстрировать довольно забавный класс событий - визуальные события.
Если у вас есть два перекрывающихся окна и вы передвинули окно на переднем плане, то вам надо перерисовать окно заднего плана. И в зависимости от природы окна, если там нарисована картинка, то проще перерисовать эту картинку. Если там какие-то буковки, то проще их перерисовать. Если вы сталкиваетесь с какими-то проблемами вашего GUI, вам стоит задуматься, что у вас с этими событиями перерисовки происходит.

У драйвера устройств события разнородны. С одной стороны прерывания устройства, с другой стороны события от других драйверов, и прочего.

Ну и вот. Существуют очереди запросов, обрабатываемых блочным или STREAMS устройством. Менеджер запустил обработчик, обработчик что-то делает, а приходит еще одно событие. Большинство диспетчеров просто ставят события в очередь. 
Можно ли что-то сделать если очередь переполнена?
ЭЭЭЭЭЭЭЭ, ну вообще говоря если у вас такое происходит, то вы не так что-то делаете. В этом случае события начинают теряться.
На сокетах такого не происходит, на сокетах у вас говорят другому концу "заткнись!".
Действительно, если у вас поток событий превосходит скорость, с которой вы их обрабатываете, то у вас так или иначе проблемы.

Диаграмма активности и диаграмма состояний - это двойственные графы. В диаграмме состояний овальчики и прямоугольники - это состояния, а переходы между ними - это активности. @Maxpona ты фоткал вроде доску, можешь картинку кинуть сюда.

Ilya_, [26.03.2025 16:01]
У нас есть состояния и события, которые их меняют.
Ну и вот, второй интересный вопрос, мы весь семестр изучали многопоточность, а обязательно ли диспетчеру событий быть многопоточным? На самом деле нет. Когда вы делаете потоки, вы можете хранить контекст в потоке и обрабатывать события. В принципе все обработчики могут вызываться из одного потока. Что вообще породило интерес к событийно-ориентированности? Вы можете получить большую часть преимуществ многопоточности без многопоточности. 
У обработчика событий нет своего контекста. Потоку создают иллюзию последовательного выполнения, обработчикам событий такую иллюзию не создают. У них теряются локальные переменные, им надо хранить состояния в определенных местах. 
Тем не менее такая схема позволяет обрабатывать все события внутри одного потока. Вот у меня коллега, который пытался сдавать событийно-ориентированный cp -r почему-то в обработчике событий поставил sleep. Событийно-ориентированная логика не должна ни на чем блокироваться. Это приобретает очень интересный аспект, когда мы пытаемся сделать многопоточную событийно-ориентированность. И обработчики тогда должны понимать, что их могут позвать из разных нитей.
Если это делать по-крестьянски, то есть повесить семафор, мы получаем то, чего я советовал вам не делать. Куды крестьянину податься, у нас с вами времени скорее всего не хватит обсудить.
Один из забавных подходов - можно делать внутреннюю очередь. Вы можете стать менеджером событий внутри своего объекта. Сказать нити, если вас второй раз зовут, что тут еще одно событие появилось. 
Нить - это дорого. Если вы делаете множество потоков на множество событий, вы опухнете в большинстве языков.
Самый интересный в этом плане язык, это го. Вся событийная ориентированность оказывается спрятана внутри гошного рантайма. Она спрятана хорошо, но это не совсем то, чему я вас пытаюсь научить. Нить - это дорого, а в событийно-ориентированной архитектуре мы можем один и тот же контекст переиспользовать.

Менеджер событий. В первом приближении можно сказать, что он и есть фреймворк. Он вызывает обработчики событий, если событий слишком много, он выстраивает очередь. Асинхронная очередь событий это умный способ сказать, что у вас менеджер событий на самом деле многопоточный.

Поскольку у вас обработчики событий одного и того же объекта могут позваться из разных нитей, вас ждет множество приколов. Многопоточные событийно-ориентированные архитектуры - это и есть, ну, так сказать, все самое интересное только на них и пишется.

Чем хороша событийно-ориентированная архитектура? Можно обрабатывать много событий в одном потоке. И можно получить значительную часть преимуществ многопоточности, не связываясь с ней. Вы можете обрабатывать много событий в небольшом числе потоков, что хорошо. 

Главный сценарий - когда у вас много событий. Либо графический интерфейс, в котором пользователь много может тыкать, или высоконагруженный сервер.
Недостаток - обработчик не должен делать длинных вычислений и не должен вызывать ничего блокирующегося. Поэтому код, который вы привыкли вызывать во всех остальных местах, тут не годиться. Даже отдельные библиотеки, которые такой код содержат, вы должны запускать в отдельных нитях.

Один из главных тезисов, который я пытаюсь донести до вас, когда вы пишете многопоточный код, вам надо непрерывно думать головой, поскольку те паттерны, к которым вы привыкли, вас могут привести к катастрофе. Также и когда вы пишете событийно-ориентированный код, вам надо переучиваться. Мы пытались вас в это немного погрузить, как раз пытаясь вам на первом курсе давать как императивное, так и декларативное программирование. Несколько режимов работы у мозга приобрести и уметь переключаться с одного на другой - это полезно. Поскольку событийно-ориентированное приложение надо писать - думать головой, поэтому я оптимистичен на тему замены программистов тем, что сейчас называют искуственным интеллектом.

Ilya_, [26.03.2025 16:01]
Дальше у меня идет тема уже более прикладная к нашей теме практикума, это как все эти соображения применить в нашем практикуме. А именно - задачки, у нас есть несколько задачек. Так называемый кэширующий прокси. Сетевой сервер - приложение, ориентированное на ввод-вывод. Событие для него - приход данных с каких-то сокетов. Проще всего в качестве ядра менеджера событий использовать знакомые нам select/poll. Когда ничего нет, он блокируется, когда что-то есть, он вам выдает что ест. Событием является готовность сокета к чтению или записи. Также вы можете написать менеджер событий вокруг асинхронного ввода вывода, где у вас будут событиями являться сами операции чтения-записи. Также у нас есть порты событий солярис, которые мы не проходим, но никто на них не пытался писать.

Как все-таки писать проксю? Давайте сделаем перерыв.

Итак. Чтобы написать прокси, надо знать HTTP. 
HTTP 2.1 и 2.3 это две большие разницы. И поддержки HTTP 2.3 вы не реализуете в разумные сроки. С одной стороны есть куча готовых библиотек, в go даже есть стандартная библиотека, которая HTTP поддерживает, но её использование вам запрещено. Что в общем-то перекрывает вам дорогу к сколько-нибудь продвинутым диалектам, включая HTTP 2.3. Это сделано немножко осознанно, чтобы вы не могли взять готовый.
Сам протокол stateless. В самом протоколе вы шлете запрос. На самом деле лучше чтобы вы кэшировали запросы get head, браузер шлет этот тэг для управления кэшированием. Также есть поля, которые управляют кэшированием, но в течение семестра вы их сделать не успеете. Сам по себе протокол - вы шлете запрос, он состоит из строки запроса и дополнительных полей. Поля похожи на заголовок SMTP, вида имя: значение.
Заголовки могут содержать только ASCII текст. Если бинарные данные, то чаще всего используется armlink с кодировкой base64. 
В достаточно большой части заголовков HTTP употребляется mime type. Изначально это было расширение протокола SMTP, чтобы можно было передавать бинарные данные. И они же используются протоколом HTTP, чтобы указать, что вы собственно передаете. Также используются заголовки, управляющие кэшэм. 
Самый веселые заголовок - так называемые cookie. Сам по себе протокол HTTP он stateless - то есть каждый запрос обрабатывается независимо от остальных. Однако любое нетривиальное приложение этого не делает. Клиент отправляет куку серверу, и сервер может узнавать, что это тот же самый клиент и та же самая сессия.

Это делать не обязательно, можно эти куки руками стереть, можно их посмотреть и избирательно забыть. Тем не менее на вот этих куках строится семантика сессии. Куки используются для аутентификации. Я не знаю, будет ли у вас курс веб разработки, где это осмысленно рассказывают.

Вот, вы делаете запрос, вам присылают ответ. В простейшем случае это static content, какой-то файл, который лежит на сервере. Это может быть текст, html, yaml и все что угодно. Это могут быть просто бинарные данные, и, ээ, и вот.

К этому ответу обязаны быть соответствющие поля mime, content type и encoding. Если это текст, то в какой он кодировке, если это картинка, то какого она формата. 
Запросы GET и HEAD, которые мы кэшируем, не имеют тела.
Запросы PUT и POST, которые отправляют данные, у них есть кодировка и вы обязаны эти поля указывать в заголовке нашего запроса. Наш прокси кэшировать эти запросы не имеет права, когда вы будете его тестировать, вы можете увидеть, что в браузере какой-нибудь джаваскрипт это все обрабатывает.

Дальше начинается чехарда, потому что в HTTP 1.0, которым я вас заставляю пользоваться, вы посылаете запрос, вам возвращают ответ, и все. Даже если вам приходит ответ без длинны, он считается законченным, когда соединение разорвется.

Ilya_, [26.03.2025 16:01]
Однако в HTTP 1.1 появился ряд фич, в том числе появилась фича под названием connection блрдлб.
Вы шлете запрос, получаете ответ, дальше соединение не закрывается и вы можете послать другой запрос. 
Тогда вам обязаны ответить длину, и вы можете сделать несколько запросов, не закрывая соединение. Это сильно усложняет кодирование.
Поэтому я настаиваю на том, чтобы вы и в проксе и в клиенте всегда говорили, что "я HTTP 1.1, не надо мне всех этих фокусов".

Все эти фишки 1.1, много фишек в 1.1 появилось, которые вы не сделаете в отведенное по учебному плану время. Все, что вам надо сделать, это чтобы ваш прокси корректно себя идентифицировал и клиенту и серверу, как поддерживающий HTTP 1.0.

Клиентское соединение.
Ждем входящего соединение. Получаем его.
Если вы получаете запрос HTTP 1.1, то вы все равно должны ответить 200 OK HTTP 1.0.

Сейчас ситуация немножко одичала, потому что 1.1 не то чтобы считается deprecated, но довольно много утилит, которые его неправильно поддерживают.

в 1.1. connection pooling, вы можете отправлять запросы только последовательно. В http 2.0 вы можете отправлять запросы, не дожидаясь ответа на предыдущий. И ответы вам могут приходить кусочками, кусок одного ответа, кусок другого. Преимущества очевидны, но написать и отладить все это корректно вы за семестр не сможете.
2.0 это очень интересная фишка, а 3.0 я отношу к разряду извращений. Они решили отказаться от TCP и перейти на UDP. Протокол TCP пятьдесят лет отлаживали, чтобы он хорошо себя вел. В TCP все это предусмотрено, и вот они пересаживаются на UDP, либо они теперь должны изобрести TCP самостоятельно.

Как я уже говорил, запросы могут быть всякие интересные. После запроса идет ответ. Как я уже говорил, get запросы в 1.0 вообще нет обязательных полей, на практике в поле запроса вам надо слать host. Потому что очень много в интернете серверов, которые определяет, что вам отдавать, по host заголовку, потому что имя, которое вы шлете в запросе, до сервера не доходит.

Очень важно понимать про URL и URI. 
URL - вся фигня вместе с https://

Два запроса, которые можно кэшировать - GET и HEAD. GET получает контент, HEAD получает заголовок без контента. Если клиент знает, что контент большой, он может сначала попросить HEAD, и если ничего не изменилось, он может просто ответить тот же самый контент. В записи запроса вы должны запоминать не только контент, но и заголовок. Поддерживается ли тип запроса, вы должны посмотреть.
В HTTP есть такой веселый запрос, называется CONNECT. Когда у вас идет HTTPS соединение, то у вас шифрование end to end. Промежуточные звенья не должны обладать информацией, чтобы расшифровать. Вы делаете запрос CONNECT, и его надо разрешить по 443 порту. И если вы разрешите его через другой порт, вы превратитесь в то, что называется open relay, за который вам безопасники открутят бошку. Поэтому CONNECT мы не принимаем.

У вас приходит запрос, вы решаете, кэшируется он или нет. Если не кэшируется, просто отправляете его серверу. Если он кэшируется, вам надо посмотреть, есть ли он в кэшэ. Если в кэшэ его нет, вы шлете запрос, вас может ждать приключение, если вам не ответят размера. Если ответили - просто аллоцируете память и записываете его туда. Интересный момент, когда запись кэша еще недокачана и к ней делаются дополнительные запросы. Если она качается долго, то какой-нибудь один клиент может отвалиться. Он отваливается, и тут начинается что-то интересное - а вам-то что делать? С точки зрения архитектуры проще докачать его. С точки зрения пользователя это может быть плохая идея. 
Первых троих, кто прокси будет сдавать, на это не тестировать.
Ситуация - большой файл качают через вас, открывают сессию второй раз и качают снова тот же самый файл. 

Третий прикол - вы обязаны отказываться кэшировать слишком большие объекты, потому что память у нас на солярисе не резиновая, а прокси обязан хранить состояние только в памяти. Иначе если прокси упадет, вы обязаны поддерживать кэш в консистентном состоянии.
Ну и вот, соответственно, ну да, вот-вот. Можете ссылаться на слайд.